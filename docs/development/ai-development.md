# AI 开发指南

## 1. Cursor Agent 开发流程

### 1.1 开发阶段
1. 项目初始化阶段
   - 产品设计
   - 版本计划
   - 开发环境搭建

2. 项目计划阶段
   - 设计开发计划
   - 任务进度跟踪
   - 质量控制机制

3. 项目实施阶段
   - 原子功能分解
   - 功能开发
   - 测试与文档

### 1.2 AI 辅助开发
- 使用 Cursor IDE 进行开发
- 遵循 AI 提示词规范
- 保持代码质量和一致性

## 2. AI 提示词规范

### 2.1 基本原则
- 清晰明确的指令
- 完整的上下文信息
- 具体的输出要求
- 错误处理机制

### 2.2 提示词模板
1. 功能开发
```
开发任务：[具体功能描述]
输入：[需要的输入数据]
输出：[期望的输出结果]
要求：
- [具体要求1]
- [具体要求2]
- [具体要求3]
```

2. 代码审查
```
审查范围：[文件或代码块]
关注点：
- 代码质量
- 性能优化
- 安全问题
- 最佳实践
```

3. 问题修复
```
问题描述：[具体问题]
当前行为：[现有表现]
期望行为：[期望结果]
相关代码：[代码位置]
```

### 2.3 最佳实践
1. 代码生成
   - 提供完整上下文
   - 指定具体需求
   - 包含错误处理
   - 要求代码注释

2. 代码优化
   - 明确优化目标
   - 提供性能指标
   - 指定约束条件
   - 要求兼容性

3. 问题诊断
   - 提供错误信息
   - 描述复现步骤
   - 列出尝试方案
   - 指定期望结果

## 3. AI 开发规范

### 3.1 代码生成规范
- 使用TypeScript类型
- 遵循项目架构
- 保持代码风格
- 添加必要注释

### 3.2 代码审查规范
- 性能检查
- 安全审查
- 代码质量
- 测试覆盖

### 3.3 文档生成规范
- API文档
- 使用说明
- 开发指南
- 部署文档

## 4. AI 协作流程

### 4.1 开发流程
1. 需求分析
   - 使用AI辅助分析需求
   - 生成功能规格说明
   - 创建任务分解清单

2. 功能开发
   - AI生成代码框架
   - 人工审查和修改
   - AI优化和完善

3. 测试验证
   - AI生成测试用例
   - 自动化测试执行
   - 问题诊断和修复

### 4.2 代码审查
1. 自动检查
   - 代码风格
   - 潜在问题
   - 性能瓶颈

2. AI审查
   - 逻辑检查
   - 最佳实践
   - 安全漏洞

3. 人工确认
   - 业务逻辑
   - 架构设计
   - 最终决策

### 4.3 文档维护
1. 自动生成
   - API文档
   - 类型定义
   - 使用示例

2. AI更新
   - 文档同步
   - 示例更新
   - 版本记录

3. 人工审核
   - 内容准确性
   - 完整性检查
   - 可读性优化

## 5. 质量控制

### 5.1 代码质量
- 自动化检查
- AI代码审查
- 性能测试
- 安全扫描

### 5.2 文档质量
- 完整性检查
- 准确性验证
- 可读性优化
- 版本控制

### 5.3 测试质量
- 测试覆盖率
- 自动化测试
- 性能测试
- 安全测试 